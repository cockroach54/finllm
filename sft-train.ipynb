{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWnZuU7PVtZF"
   },
   "source": [
    "# SFT (Supervised Fine Tuning) for LLM\n",
    "- ê¸ˆìœµì–¸ì–´ëª¨ë¸ í•™ìŠµ\n",
    "- instruction tuning\n",
    "- ì¶”ë¡ ëŠ¥ë ¥ í–¥ìƒ ë° ì§€ì‹œì— ë§ëŠ” ë‹µë³€ í¬ë§·íŒ… ëª©ì "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNfOabrCVtZH"
   },
   "source": [
    "## ëª¨ë¸ ë° ë°ì´í„°ì…‹ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = 'hf_****'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sK96swGiVtZH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2024.12.2: Fast Qwen2 patching. Transformers:4.47.0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 80GB HBM3. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18431a84f2254d51b3a8f022fec4a237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 1500\n",
    "# max_seq_length = 1024\n",
    "# max_seq_length = 2000\n",
    "dtype = None # Noneìœ¼ë¡œ ì§€ì •í•  ê²½ìš° í•´ë‹¹ ì»´í“¨íŒ… ìœ ë‹›ì— ì•Œë§ì€ dtypeìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. Tesla T4ì™€ V100ì˜ ê²½ìš°ì—ëŠ” Float16, Ampere+ ì´ìƒì˜ ê²½ìš°ì—ëŠ” Bfloat16ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\n",
    "load_in_4bit = False # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ì„œëŠ” 4bit ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ì‹¤ ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„ ì–¸\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"lsw0570168/krx-q25-7b-base-v7.2-fft\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token, # gated modelì„ ì‚¬ìš©í•  ê²½ìš° í—ˆê¹…í˜ì´ìŠ¤ í† í°ì„ ì…ë ¥í•´ì£¼ì‹œê¸¸ ë°”ë¼ê² ìŠµë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u2mlY9pMVtZH"
   },
   "outputs": [],
   "source": [
    "# lora í•™ìŠµì‹œ í™œì„±í™”\n",
    "\n",
    "# model = FastLanguageModel.get_peft_model(\n",
    "#     model,\n",
    "#     r = 32,  # 16, # 0ì„ ë„˜ëŠ” ìˆ«ìë¥¼ ì„ íƒí•˜ì„¸ìš”. 8, 16, 32, 64, 128ì´ ì¶”ì²œë©ë‹ˆë‹¤.\n",
    "#     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "#                       \"gate_proj\", \"up_proj\", \"down_proj\",], # target moduleë„ ì ì ˆí•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "#     lora_alpha = 16,\n",
    "#     lora_dropout = 0, # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, 0ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "#     bias = \"none\",    # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, \"none\"ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "#     use_gradient_checkpointing = \"unsloth\", # ë§¤ìš° ê¸´ contextì— ëŒ€í•´ True ë˜ëŠ” \"unsloth\"ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\n",
    "#     random_state = 42,\n",
    "#     use_rslora = False,\n",
    "#     loftq_config = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loDn97x9VtZH"
   },
   "source": [
    "## ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 1949\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import random\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    err_cnt = 0\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data.append(json.loads(line.strip()))\n",
    "            except Exception as e:\n",
    "                err_cnt += 1\n",
    "    if err_cnt > 0:\n",
    "        print(f\"err line count: {err_cnt}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "with open('./sft_kbench-p.json', 'r') as f:\n",
    "    dd = json.load(f)\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "ds = Dataset.from_dict(\n",
    "    {'formatted_text': [f\"{x}{EOS_TOKEN}\" for x in dd]}\n",
    ")#.shuffle(seed=777).select(range(2000))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒ ë¬¸ì œë¥¼ ì½ê³  ì •ë‹µìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹œìš”.\n",
      "### ì§ˆë¬¸: ë‹¤ìŒ ë°ì´í„°í”„ë ˆì„ì—ì„œ 'GDP' ê°’ì´ ê°€ì¥ í° í•´ì˜ 'Year' ê°’ì„ êµ¬í•˜ì„¸ìš”.\n",
      "\n",
      "### df.head()\n",
      "|    | Year | GDP      |\n",
      "|----|------|----------|\n",
      "|  0 | 2010 | 15000.0  |\n",
      "|  1 | 2011 | 15500.5  |\n",
      "|  2 | 2012 | 16000.0  |\n",
      "|  3 | 2013 | 16250.0  |\n",
      "|  4 | 2014 | 17000.0  |\n",
      "\n",
      "### ì„ íƒì§€:\n",
      "A. df.loc[df['GDP'].idxmax(), 'Year']\n",
      "B. df[df['GDP'] == df['GDP'].max()]['Year']\n",
      "C. df['Year'][df['GDP'].idxmax()]\n",
      "D. df.loc[df['Year'].idxmax(), 'GDP']\n",
      "E. df[df['GDP'].argmax()]['Year']\n",
      "F. df[df['GDP'] == df['GDP'].max()].Year.iloc[0]\n",
      "### ì •ë‹µ: ë¨¼ì € ì°¨ê·¼ì°¨ê·¼ í•œ ë‹¨ê³„ì”© ìƒê°í•´ë´…ì‹œë‹¤.\n",
      "#### step1. ë¬¸ì œ ì´í•´:\n",
      "ë¬¸ì œëŠ” ë°ì´í„°í”„ë ˆì„ì—ì„œ 'GDP' ê°’ì´ ê°€ì¥ í° í•´ì˜ 'Year' ê°’ì„ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°í”„ë ˆì„ì˜ íŠ¹ì • ì—´ì—ì„œ ìµœëŒ€ê°’ì„ ì°¾ê³ , ê·¸ì— í•´ë‹¹í•˜ëŠ” ë‹¤ë¥¸ ì—´ì˜ ê°’ì„ ì¶”ì¶œí•˜ëŠ” ë¬¸ì œë¡œ, íŒë‹¤ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "#### step2. ê° ë³´ê¸°ë³„ ë¬¸ì œ í’€ì´:\n",
      "ê° ë³´ê¸°ë³„ë¡œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "A. df.loc[df['GDP'].idxmax(), 'Year'] - 'GDP'ì˜ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ 'Year' ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "B. df[df['GDP'] == df['GDP'].max()]['Year'] - 'GDP'ì˜ ìµœëŒ€ê°’ê³¼ ê°™ì€ í–‰ì„ í•„í„°ë§í•˜ì—¬ 'Year' ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "C. df['Year'][df['GDP'].idxmax()] - 'GDP'ì˜ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ 'Year' ì—´ì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "D. df.loc[df['Year'].idxmax(), 'GDP'] - 'Year'ì˜ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ 'GDP' ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì˜ëª»ëœ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "E. df[df['GDP'].argmax()]['Year'] - 'argmax()'ëŠ” numpy í•¨ìˆ˜ë¡œ, íŒë‹¤ìŠ¤ì—ì„œëŠ” 'idxmax()'ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ëª»ëœ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "F. df[df['GDP'] == df['GDP'].max()].Year.iloc[0] - 'GDP'ì˜ ìµœëŒ€ê°’ê³¼ ê°™ì€ í–‰ì„ í•„í„°ë§í•˜ì—¬ 'Year' ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "#### step3. ì „ì²´ í’€ì´ ê²€ì¦:\n",
      "A, B, C, FëŠ” ëª¨ë‘ 'GDP'ì˜ ìµœëŒ€ê°’ì— í•´ë‹¹í•˜ëŠ” 'Year' ê°’ì„ ì˜¬ë°”ë¥´ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤. DëŠ” ì˜ëª»ëœ ì—´ì„ ì°¸ì¡°í•˜ê³  ìˆìœ¼ë©°, EëŠ” ì˜ëª»ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "#### step4. ìµœì¢… ì •ë‹µ:\n",
      "ì˜¬ë°”ë¥¸ ì •ë‹µì€ A, B, C, Fì…ë‹ˆë‹¤. ì´ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ ë©ë‹ˆë‹¤.\n",
      "### ì •ë‹µ: A<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(ds['formatted_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 2200\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd4 = load_jsonl('./qa_all.jsonl')\n",
    "dd4 = [aaa for aaa in dd4 if len(aaa['question']) > 230]\n",
    "dd42 = load_jsonl('./error_note.jsonl')\n",
    "dd4 = dd4 + dd42 + dd42\n",
    "ds4 = Dataset.from_dict(\n",
    "    {'formatted_text': [f\"{x['question']}\\n\\n{x['answer']}{EOS_TOKEN}\" for x in dd4]}\n",
    ").shuffle(seed=777)#.select(range(5000))\n",
    "ds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = load_dataset(\"kuotient/orca-math-korean-preference\", split='train') \\\n",
    "    .rename_columns({'question': \"prompt\", \"answer\": \"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 2418\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = load_dataset(\"ChuGyouk/argilla-distilabel-math-preference-dpo-korean\", split='train') \\\n",
    "    .rename_columns({'instruction_ko': \"prompt\", \"chosen_response_ko\": \"response\", \"chosen_response\":\"response_en\"}) \\\n",
    "    .select_columns(['prompt', 'response', 'response_en'])\n",
    "\n",
    "rr2 = [\n",
    "    f\"ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì¥ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì‹œì˜¤.\\n\\n### í•œêµ­ì–´:\\n{x['response']}\\n\\n### ì˜ì–´:\\n{x['response_en']}\" \\\n",
    "    for x in rs2.to_list()[:int(len(rs2)/2)]\n",
    "]\n",
    "rr22 = [\n",
    "    f\"Translate English statement below to Korean.\\n\\n### English:\\n{x['response_en']}\\n\\n### Korean:\\n{x['response']}\" \\\n",
    "    for x in rs2.to_list()[int(len(rs2)/2):]\n",
    "]\n",
    "tmp = Dataset.from_dict({\n",
    "    \"prompt\": ['']*len(rr2+rr22), \"response\": rr2+rr22\n",
    "})\n",
    "\n",
    "rs2 = concatenate_datasets([rs2]) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777)#.select(range(2000))\n",
    "rs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = load_dataset(\"MarkrAI/KoCommercial-Dataset\", split='train') \\\n",
    "    .rename_columns({'instruction':\"prompt\", \"output\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs4 = load_dataset(\"dhruvnathawani/gretelai_synthetic-gsm8k-reflection-405b_validated_with_o1-mini_validation_only\", split='train') \\\n",
    "    .rename_columns({'question':\"prompt\", \"answer\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs5 = load_dataset(\"heegyu/CoT-collection-ko\", split='train') \\\n",
    "    .select_columns(['source', 'rationale']) \\\n",
    "    .rename_columns({'source':\"prompt\", \"rationale\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs6 = load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split='train') \\\n",
    "    .select_columns(['document', 'summary']) \\\n",
    "    .rename_columns({'document':\"prompt\", \"summary\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rr6 = [\n",
    "    f\"ë‹¤ìŒ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ìš”ì•½í•˜ì‹œì˜¤.\\n\\n### ë‰´ìŠ¤ë³¸ë¬¸:\\n{x['prompt']}\\n\\n### ìš”ì•½:\\n{x['response']}\" \\\n",
    "    for x in rs6.to_list()\n",
    "]\n",
    "rs6 = Dataset.from_dict({\"prompt\": ['']*len(rr6), \"response\": rr6}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777)#.select(range(2000))\n",
    "rs6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af082a867f6d419ba9f05ef4d84a78c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'formatted_text'],\n",
       "    num_rows: 2250\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_format = \"{}\\n\\n{}\"\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"prompt\"]\n",
    "    outputs = examples[\"response\"]\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        text = prompt_format.format(instruction, output) + EOS_TOKEN # ë§ˆì§€ë§‰ì— eos tokenì„ ì¶”ê°€í•´ì¤Œìœ¼ë¡œì¨ ëª¨ë¸ì´ ì¶œë ¥ì„ ëë§ˆì¹  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
    "        # text = 'axf'*10000+prompt_format.format(instruction, output) + EOS_TOKEN # ë§ˆì§€ë§‰ì— eos tokenì„ ì¶”ê°€í•´ì¤Œìœ¼ë¡œì¨ ëª¨ë¸ì´ ì¶œë ¥ì„ ëë§ˆì¹  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
    "        texts.append(text)\n",
    "    return { \"formatted_text\" : texts, }\n",
    "pass\n",
    "\n",
    "ds_comb = concatenate_datasets([rs, rs2, rs3, rs4, rs5, rs6])\n",
    "\n",
    "_dataset = ds_comb.map(formatting_prompts_func, batched = True,)\n",
    "_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 4511\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = concatenate_datasets([ds, _dataset]) \\\n",
    "            .select_columns(['formatted_text']) \\\n",
    "            .shuffle(seed=777)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒ ë¬¸ì œë¥¼ ì½ê³  ì •ë‹µìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹œìš”.\n",
      "### ì§ˆë¬¸: ë‹¤ìŒ ì¤‘ ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜³ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€?\n",
      "### ì„ íƒì§€:\n",
      "A. ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì€ ìë³¸ì‰ì—¬ê¸ˆìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
      "B. ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì€ ê¸°íƒ€í¬ê´„ì†ìµìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
      "C. ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì€ ë‹¹ê¸°ì†ìµìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
      "D. ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì€ ë¯¸ì²˜ë¶„ì´ìµì‰ì—¬ê¸ˆìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
      "### ì •ë‹µ: \n",
      "1. ë¬¸ì œ ìœ í˜•: ì •ì˜ ê¸°ë°˜\n",
      "\n",
      "2. ë¬¸ì œ í’€ì´ ì „ëµ:\n",
      "   - ì •ì˜ ê¸°ë°˜ ë¬¸ì œì˜ ê²½ìš°, ê´€ë ¨ ìš©ì–´ì˜ ì •ì˜ë‚˜ ì›ì¹™ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ë¬¸ì œì—ì„œ ì–¸ê¸‰ëœ ìš©ì–´(ì˜ˆ: ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµ)ì— ëŒ€í•œ íšŒê³„ ê¸°ì¤€ì´ë‚˜ ì›ì¹™ì„ ê²€í† í•˜ì—¬ ì˜¬ë°”ë¥¸ ì²˜ë¦¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. ì„¸ë¶€ í’€ì´ ê³¼ì •:\n",
      "   - ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œì€ ê¸°ì—…ì´ ë‹¨ê¸°ì ì¸ ì‹œì„¸ ì°¨ìµì„ ëª©ì ìœ¼ë¡œ ë³´ìœ í•˜ëŠ” ê¸ˆìœµìì‚°ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¦ê¶Œì€ ê³µì •ê°€ì¹˜ë¡œ í‰ê°€ë˜ë©°, í‰ê°€ì†ìµì€ ë‹¹ê¸°ì†ìµìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.\n",
      "   - ì´ëŠ” êµ­ì œíšŒê³„ê¸°ì¤€(IFRS) ë° í•œêµ­ì±„íƒêµ­ì œíšŒê³„ê¸°ì¤€(K-IFRS)ì—ì„œ ê·œì •í•˜ëŠ” ë°”ì— ë”°ë¼, ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œì˜ í‰ê°€ì†ìµì€ ì†ìµê³„ì‚°ì„œì— ë°˜ì˜ë˜ì–´ ë‹¹ê¸°ì†ìµìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
      "   - ë”°ë¼ì„œ, ë³´ê¸° ì¤‘ì—ì„œ ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì„ ë‹¹ê¸°ì†ìµìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤ê³  ì„¤ëª…í•œ ì„ íƒì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìµœì¢…ì ìœ¼ë¡œ, ì •ë‹µì€ C. ë‹¨ê¸°ë§¤ë§¤ì¦ê¶Œ í‰ê°€ì†ìµì€ ë‹¹ê¸°ì†ìµìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
      "### ì •ë‹µ: C<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['formatted_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import seaborn as sns\n",
    "\n",
    "# res3 = []\n",
    "# for x in tqdm(dataset['formatted_text']):\n",
    "#     res3.append(len(tokenizer.encode(x)))\n",
    "\n",
    "# print(len([x for x in res3 if x>max_seq_length]))\n",
    "# sns.histplot(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ë„ˆë¬´ ê¸´ ë°ì´í„°ëŠ” ì˜ëª»ëœ ë°ì´í„°ì¼ ê°€ëŠ¥ì„± í¬ë¯€ë¡œ ì œì™¸!\n",
    "\n",
    "# idxs = [i for i,x in enumerate(res3) if x>3000]\n",
    "# print(len(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.filter(lambda x, i: i not in idxs, with_indices=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNT3z9nNVtZH"
   },
   "source": [
    "## ëª¨ë¸ í•™ìŠµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import wandb\n",
    "\n",
    "# ê³ ì • ì„¤ì •\n",
    "os.environ['WANDB_PROJECT']=\"krx\"\n",
    "os.environ['WANDB_API_KEY']=\"****\"\n",
    "os.environ['WANDB_ENTITY']=\"****\"\n",
    "\n",
    "# ê°œë³„ ì„¤ì •\n",
    "os.environ['WANDB_TAGS']=\"\"\n",
    "run_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "n7K5p11fVtZH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251334f522a4488ba11c98a1293b7ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/4511 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 16,\n",
    "    packing = False, # Trueë¡œ ì„¤ì •í•˜ë©´ ì§§ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ë” ë¹ ë¥¸ í•™ìŠµ ì†ë„ë¡œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "    args = TrainingArguments( # TrainingArgumentsëŠ” ìì‹ ì˜ í•™ìŠµ í™˜ê²½ê³¼ ê¸°í˜¸ì— ë”°ë¼ ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "        per_device_train_batch_size = 2,  # A10(22g) - aws\n",
    "        gradient_accumulation_steps = 8,        \n",
    "        # per_device_train_batch_size = 48,  # H100(80g)\n",
    "        # gradient_accumulation_steps = 1,\n",
    "        # warmup_steps = 100,\n",
    "        warmup_ratio = 0.06,\n",
    "        num_train_epochs = 2,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-5,\n",
    "        # learning_rate = 1e-5,\n",
    "        # learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_hf\",\n",
    "        # optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",  # \"linear\",\n",
    "        seed = 777,\n",
    "        output_dir = \"outputs_sft\",\n",
    "        save_strategy = \"no\",\n",
    "        # save_steps = 1000,\n",
    "        # save_total_limit = 2,\n",
    "        # report_to=\"none\",\n",
    "        report_to = \"wandb\",\n",
    "        run_name = run_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H100 80GB HBM3. Max memory = 79.109 GB.\n",
      "14.689 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer_stats = trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb ë¡œê¹… ì¢…ë£Œ\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9S7MWeVtZI"
   },
   "source": [
    "## 5. ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [],
   "source": [
    "# # LoRA Adapter ì €ì¥\n",
    "# model.save_pretrained(\"lora_model\")\n",
    "# tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [],
   "source": [
    "# # # Merged model ì €ì¥\n",
    "# local_model_save_path = \"sft-v7.2-1206-hq2-prc3\"\n",
    "# model.save_pretrained_merged(local_model_save_path, tokenizer, save_method = \"merged_16bit\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = lsw0570168.\n",
      "We shall truncate lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6 to krx-q25-7b-sft-v7.2-1206-hq2-prc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 671.96 out of 1007.38 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 993.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving to organization with address lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e41de8fced44f2a891dd8ce633f1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da9e2fb23d6454ba1ee216260e6750e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merged model ì—…ë¡œë“œ\n",
    "import requests\n",
    "\n",
    "deploy_name = 'lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6'\n",
    "model.push_to_hub_merged(deploy_name, tokenizer, save_method = \"merged_16bit\", token = hf_token) # ê°œì¸ huggingface tokenì„ ì‚¬ìš©í•˜ì—¬ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZl4bf7ZVtZI"
   },
   "source": [
    "## 6. ëª¨ë¸ ì¶”ë¡  ë° ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sHa2tCFgVtZI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒ ë¬¸ì œë¥¼ ì½ê³  ì •ë‹µìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹œìš”.\n",
      "\n",
      "### ì§ˆë¬¸:\n",
      "ì˜ë¬´ ìœ„ë°˜ì˜ íš¨ê³¼ë¡œ ë³´í—˜ìê°€ ê·¸ ë³´í—˜ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆë‹¤ê³  ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ì‹œì˜¤. (ë‹¤íˆ¼ì´ ìˆëŠ” ê²½ìš° íŒë¡€ì— ë”°ë¦„)**\n",
      "\n",
      "### ì„ íƒì§€:\n",
      "A. ë³´í—˜ê³„ì•½ ë‹¹ì‹œ, ë³´í—˜ê³„ì•½ìë‚˜ í”¼ë³´í—˜ìê°€ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì¤‘ìš”í•œ ì‚¬í•­ì„ ê³ ì§€í•˜ì§€ ì•Šê±°ë‚˜ ë¶€ì‹¤í•˜ê²Œ ê³ ì§€í•œ ê²½ìš°  \n",
      "B. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì ë˜ëŠ” í”¼ë³´í—˜ìê°€ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ì‚¬ì‹¤ì„ ì•Œì•˜ìŒì—ë„ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°  \n",
      "C. ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìê°€ ë³´í—˜ì‚¬ê³ ì˜ ë°œìƒì„ ì•Œì•˜ì„ ë•Œ, ì´ë¥¼ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°  \n",
      "D. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìì˜ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ê²½ìš°\n",
      "### ì •ë‹µ:\n",
      "#### Step 1: ë¬¸ì œì˜ ì˜ë„ íŒŒì•… ë° ìœ í˜• ë¶„ë¥˜\n",
      "- **ë¬¸ì œì˜ ì˜ë„**: ë³´í—˜ê³„ì•½ì—ì„œì˜ ì˜ë¬´ ìœ„ë°˜ìœ¼ë¡œ ì¸í•´ ë³´í—˜ìê°€ ë³´í—˜ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆëŠ” ê²½ìš°ë¥¼ ì‹ë³„í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.\n",
      "- **í•µì‹¬ ê°œë…**: ë³´í—˜ê³„ì•½ì˜ í•´ì§€ ì‚¬ìœ , ì˜ë¬´ ìœ„ë°˜, ê³ ì§€ì˜ë¬´, í†µì§€ì˜ë¬´\n",
      "- **ë¬¸ì œ ìœ í˜•**: ë¶„ë¥˜ ë¬¸ì œ - ì£¼ì–´ì§„ ë³´ê¸° ì¤‘ ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë³´í—˜ê³„ì•½ í•´ì§€ ì‚¬ìœ ë¥¼ ì°¾ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.\n",
      "\n",
      "#### Step 2: í’€ì´ ê³„íš ìˆ˜ë¦½\n",
      "- ê° ë³´ê¸°ì—ì„œ ì œì‹œëœ ìƒí™©ì´ ìƒë²•ì— ëª…ì‹œëœ ë³´í—˜ê³„ì•½ í•´ì§€ ì‚¬ìœ ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "- ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ì°¾ê¸° ìœ„í•´ ê° ë³´ê¸°ë¥¼ ê²€í† í•©ë‹ˆë‹¤.\n",
      "\n",
      "#### Step 3: ê° ë³´ê¸°ë³„ ë¬¸ì œ í’€ì´ ë° ê²€í† \n",
      "- **A. ë³´í—˜ê³„ì•½ ë‹¹ì‹œ, ë³´í—˜ê³„ì•½ìë‚˜ í”¼ë³´í—˜ìê°€ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì¤‘ìš”í•œ ì‚¬í•­ì„ ê³ ì§€í•˜ì§€ ì•Šê±°ë‚˜ ë¶€ì‹¤í•˜ê²Œ ê³ ì§€í•œ ê²½ìš°**\n",
      "  - ìƒë²• ì œ643ì¡°ì— ë”°ë¥´ë©´, ë³´í—˜ê³„ì•½ìë‚˜ í”¼ë³´í—˜ìê°€ ì¤‘ìš”í•œ ì‚¬í•­ì„ ê³ ì§€í•˜ì§€ ì•Šê±°ë‚˜ ë¶€ì‹¤í•˜ê²Œ ê³ ì§€í•œ ê²½ìš°, ë³´í—˜ìëŠ” ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ê²½ìš°ëŠ” ìƒë²•ì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "- **B. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì ë˜ëŠ” í”¼ë³´í—˜ìê°€ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ì‚¬ì‹¤ì„ ì•Œì•˜ìŒì—ë„ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°**\n",
      "  - ìƒë²• ì œ644ì¡°ì— ë”°ë¥´ë©´, ë³´í—˜ê¸°ê°„ ì¤‘ì— ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ì‚¬ì‹¤ì„ ì•Œì•˜ìŒì—ë„ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°, ë³´í—˜ìëŠ” ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ê²½ìš°ë„ ìƒë²•ì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "- **C. ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìê°€ ë³´í—˜ì‚¬ê³ ì˜ ë°œìƒì„ ì•Œì•˜ì„ ë•Œ, ì´ë¥¼ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°**\n",
      "  - ìƒë²• ì œ645ì¡°ì— ë”°ë¥´ë©´, ë³´í—˜ì‚¬ê³ ì˜ ë°œìƒì„ ì•Œì•˜ì„ ë•Œ ì´ë¥¼ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°, ë³´í—˜ìëŠ” ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ê²½ìš°ë„ ìƒë²•ì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "- **D. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìì˜ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ê²½ìš°**\n",
      "  - ìƒë²•ì—ëŠ” ë³´í—˜ê¸°ê°„ ì¤‘ì— ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìì˜ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ê²½ìš°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í•´ì§€ ì‚¬ìœ ë¡œ ê·œì •í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ê²½ìš°ëŠ” ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì‚¬ìœ ì…ë‹ˆë‹¤.\n",
      "\n",
      "#### Step 4: í’€ì´ ì¢…í•©, ê²€í†  ë° ê°œì„ \n",
      "- ê° ë³´ê¸°ë¥¼ ê²€í† í•œ ê²°ê³¼, Dê°€ ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë³´í—˜ê³„ì•½ í•´ì§€ ì‚¬ìœ ì…ë‹ˆë‹¤.\n",
      "- ë”°ë¼ì„œ ìµœì¢… ì •ë‹µì€ Dì…ë‹ˆë‹¤.\n",
      "\n",
      "### ì •ë‹µ: D<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "qq = '''\\\n",
    "ë‹¤ìŒ ë¬¸ì œë¥¼ ì½ê³  ì •ë‹µìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹œìš”.\n",
    "\n",
    "### ì§ˆë¬¸:\n",
    "ì˜ë¬´ ìœ„ë°˜ì˜ íš¨ê³¼ë¡œ ë³´í—˜ìê°€ ê·¸ ë³´í—˜ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆë‹¤ê³  ìƒë²•ì— ëª…ì‹œë˜ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ì‹œì˜¤. (ë‹¤íˆ¼ì´ ìˆëŠ” ê²½ìš° íŒë¡€ì— ë”°ë¦„)**\n",
    "\n",
    "### ì„ íƒì§€:\n",
    "A. ë³´í—˜ê³„ì•½ ë‹¹ì‹œ, ë³´í—˜ê³„ì•½ìë‚˜ í”¼ë³´í—˜ìê°€ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì¤‘ìš”í•œ ì‚¬í•­ì„ ê³ ì§€í•˜ì§€ ì•Šê±°ë‚˜ ë¶€ì‹¤í•˜ê²Œ ê³ ì§€í•œ ê²½ìš°  \n",
    "B. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì ë˜ëŠ” í”¼ë³´í—˜ìê°€ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ì‚¬ì‹¤ì„ ì•Œì•˜ìŒì—ë„ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°  \n",
    "C. ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìê°€ ë³´í—˜ì‚¬ê³ ì˜ ë°œìƒì„ ì•Œì•˜ì„ ë•Œ, ì´ë¥¼ ì§€ì²´ ì—†ì´ ë³´í—˜ìì—ê²Œ í†µì§€í•˜ì§€ ì•Šì€ ê²½ìš°  \n",
    "D. ë³´í—˜ê¸°ê°„ ì¤‘, ë³´í—˜ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ë³´í—˜ìˆ˜ìµìì˜ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ì¸í•´ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ í˜„ì €íˆ ë³€ê²½ë˜ê±°ë‚˜ ì¦ê°€ëœ ê²½ìš°\n",
    "### ì •ë‹µ:\n",
    "'''\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    qq,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sHa2tCFgVtZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------<v1>------\n",
      "ight)\\)ë¡œ í‘œí˜„ëœë‹¤ëŠ” ì£¼ì¥ì„ ë³´ì´ì‹œì˜¤. ì´ëŸ¬í•œ ì£¼ì¥ì„ í†µí•´ ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì˜ ì˜ë¯¸ë¥¼ ë…¼ì¦í•˜ì‹œì˜¤. \\(u \\in [t,T]\\)ì˜ ëª¨ë“  ë²”ìœ„ì—ì„œ \\(Y_u\\)ëŠ” ìƒìˆ˜ë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ \\(Y_T=y\\)ê°€ ì„±ë¦½í•˜ê³ , ë”°ë¼ì„œ ì‹œê°„ \\(t\\)ì—ì„œ ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ëŠ” \\(e^{-r(T-t)}\\max\\left(\f\n",
      "rac{y}{T}-K,0)}\\max\\left(\f\n",
      "rac{y}{T}-K,0\n",
      "\n",
      "---\n",
      "\n",
      "**ì£¼ì–´ì§„ ì¡°ê±´ê³¼ ì•„ì‹œì•ˆ ì˜µì…˜ ê°€ê²©ì˜ ê²½ê³„ ì¡°ê±´ì— ëŒ€í•œ ë…¼ì˜**\n",
      "\n",
      "---\n",
      "\n",
      "**1. ë¬¸ì œì˜ ì˜ë„ì™€ ì£¼ì–´ì§„ ì¡°ê±´ì˜ ì´í•´**\n",
      "\n",
      "- **í™•ë¥ ì  ê³¼ì •**: ì£¼ì–´ì§„ í™•ë¥ ì  ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "  \\[\n",
      "  dX_t = (-a_1 X_t + \\gamma_t) dt + dW_t\n",
      "  \\]\n",
      "  ì—¬ê¸°ì„œ \\(X_t\\)ëŠ” ì£¼ê°€ë‚˜ ìì‚° ê°€ê²©ì„ ë‚˜íƒ€ë‚´ë©°, \\(a_1\\)ì€ ìì‚°ì˜ ê°ì‡ ìœ¨, \\(\\gamma_t\\)ëŠ” ì‹œê°„ì— ë”°ë¥¸ ìì‚°ì˜ ìˆ˜ìµë¥ , \\(dW_t\\)ëŠ” Wiener ê³¼ì •(ë°±ìƒ‰ ì¡ìŒ)ì…ë‹ˆë‹¤.\n",
      "\n",
      "- **ì •ì˜**: \n",
      "  \\[\n",
      "  Y_t = \\int_{0}^{t} X_u du\n",
      "  \\]\n",
      "  ì´ëŠ” ì‹œê°„ \\(t\\)ê¹Œì§€ì˜ ìì‚° ê°€ê²©ì˜ ëˆ„ì ê°’ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "- **ê²½ê³„ ì¡°ê±´**:\n",
      "  \\[\n",
      "  v(t,0,y) = e^{-r(T-t)} \\max\\left( \\frac{y}{T} - K, 0 \\right)\n",
      "  \\]\n",
      "  ì—¬ê¸°ì„œ \\(v(t,0,y)\\)ëŠ” ì‹œê°„ \\(t\\)ì—ì„œ ìì‚° ê°€ê²©ì´ \\(X_t = 0\\)ì´ê³  ëˆ„ì ê°’ì´ \\(Y_t = y\\)ì¼ ë•Œì˜ ì˜µì…˜ ê°€ê²©ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. \\(K\\)ëŠ” í–‰ì‚¬ê°€ê²©, \\(r\\)ì€ ë¬´ìœ„í—˜ ì´ììœ¨, \\(T\\)ëŠ” ë§Œê¸°ì…ë‹ˆë‹¤.\n",
      "\n",
      "- **ì¡°ê±´**: \n",
      "  - \\(X_t = 0\\)ì´ê³  \\(Y_t = y\\)ì¼ ë•Œ, \\(X_u = 0\\)ì´ ì„±ë¦½í•˜ë©°, \\(u \\in [t, T]\\)ì˜ ëª¨ë“  ë²”ìœ„ì—ì„œ \\(Y_u\\)ëŠ” ìƒìˆ˜ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.\n",
      "  - ë”°ë¼ì„œ \\(Y_T = y\\)ê°€ ì„±ë¦½í•©ë‹ˆë‹¤.\n",
      "\n",
      "**2. ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ ê³„ì‚°**\n",
      "\n",
      "- **ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ì •ì˜**: ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì€ ë§Œê¸° ì‹œì ê¹Œì§€ì˜ ìì‚° ê°€ê²©ì˜ í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ í–‰ì‚¬ê°€ê²© \\(K\\)ì™€ ë¹„êµí•˜ì—¬ ì´ìµì„ ì–»ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤.\n",
      "- **ê°€ê²© ê³„ì‚°**: ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì— ë”°ë¼, ì‹œê°„ \\(t\\)ì—ì„œì˜ ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:\n",
      "  \\[\n",
      "  v(t, 0, y) = e^{-r(T-t)} \\max\\left( \\frac{y}{T} - K, 0 \\right)\n",
      "  \\]\n",
      "  - \\(y\\)ëŠ” ëˆ„ì ê°’ì´ë©°, \\(T\\)ëŠ” ì „ì²´ ê¸°ê°„ \\(T\\)ì— ëŒ€í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤.\n",
      "  - \\(\\max\\left( \\frac{y}{T} - K, 0 \\right)\\)ëŠ” ìì‚°ì˜ í‰ê·  ê°€ê²©ì´ í–‰ì‚¬ê°€ê²© \\(K\\)ë³´ë‹¤ í´ ë•Œì˜ ì´ìµì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "**3. ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì˜ ì˜ë¯¸ì™€ ë…¼ì¦**\n",
      "\n",
      "- **ê²½ê³„ ì¡°ê±´ì˜ ì˜ë¯¸**: \n",
      "  - \\(X_t = 0\\)ì´ê³  \\(Y_t = y\\)ì¼ ë•Œ, ì´ëŠ” ìì‚°ì˜ í˜„ì¬ ê°€ê²©ì´ 0ì´ê³  ëˆ„ì ê°’ì´ \\(y\\)ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "  - \\(X_u = 0\\)ì´ \\(u \\in [t, T]\\)ì— ëŒ€í•´ ì„±ë¦½í•œë‹¤ëŠ” ê²ƒì€ ìì‚° ê°€ê²©ì´ ì´í›„ ê¸°ê°„ ë™ì•ˆ ì¼ì •í•˜ê²Œ ìœ ì§€ëœë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "  - ë”°ë¼ì„œ \\(Y_u\\)ëŠ” ìƒìˆ˜ë¡œ ìœ ì§€ë˜ë©°, \\(Y_T = y\\)ê°€ ì„±ë¦½í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **ë…¼ì¦**:\n",
      "  - ìì‚° ê°€ê²©ì´ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ë©´, ëˆ„ì ê°’ \\(Y_t\\)ëŠ” ì‹œê°„ì— ë”°ë¼ ì¼ì •í•˜ê²Œ ì¦ê°€í•©ë‹ˆë‹¤.\n",
      "  - ë§Œê¸° ì‹œì  \\(T\\)ì—ì„œì˜ ëˆ„ì ê°’ \\(Y_t\\)ëŠ” \\(y\\)ë¡œ ì£¼ì–´ì§€ë©°, ì´ëŠ” ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ í–‰ì‚¬ê°€ê²© ê²°ì •ì— ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "  - ë”°ë¼ì„œ, ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì— ë”°ë¼ ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ëŠ” \\(e^{-r(T-t)} \\max\\left( \\frac{y}{t} - K, 0 \\right)\\)ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.\n",
      "\n",
      "**4. ê²°ë¡ **\n",
      "\n",
      "- ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì€ ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "- ìì‚° ê°€ê²©ì´ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ë¯€ë¡œ, ëˆ„ì ê°’ \\(Y_t\\)ëŠ” ì‹œê°„ì— ë”°ë¼ ì¼ì •í•˜ê²Œ ì¦ê°€í•˜ë©°, ì´ëŠ” ì•„ì‹œ\n"
     ]
    }
   ],
   "source": [
    "# qq = \"ì¼ë³¸ì˜ 2023ë…„ 6ì›” ê°œì • ìê¸ˆê²°ì œë²•ì˜ ì£¼ìš” ë³€ê²½ ì‚¬í•­ì„ ì„¤ëª…í•˜ê³ , ì´ëŸ¬í•œ ë³€ê²½ì´ ì¼ë³¸ì˜ ê¸ˆìœµì‹œì¥ ë° êµ­ì œ ê¸ˆìœµ ê·œì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë…¼ì˜í•˜ì‹œì˜¤.\"\n",
    "# qq = \"ìˆ«ìë¥¼ 10ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì€ 6ì…ë‹ˆë‹¤. ìœ¤ê¸°ëŠ” íŠ¹ì • ìˆ«ìë¡œë¶€í„° 15ë¥¼ ë¹¼ì„œ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ê·¸ê°€ ì–»ì€ ê²°ê³¼ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?\"\n",
    "# qq = \"ì •êµ­, ì§€ë¯¼, ì„ì§„, íƒœí˜•, ë‚¨ì¤€ì´ ë‚˜ë€íˆ ì„œ ìˆìŠµë‹ˆë‹¤. ì •êµ­ì€ ì§€ë¯¼ì˜ ì˜¤ë¥¸ìª½ì—, ì„ì§„ì€ ì§€ë¯¼ì˜ ì™¼ìª½ì— ì„œ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë‚¨ì¤€ì€ ì„ì§„ ì™¼ìª½ì—, ì •êµ­ì€ íƒœí˜• ì™¼ìª½ì— ì„œ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì˜¤ë¥¸ìª½ì— ì„œ ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?\"\n",
    "# qq = \"ìˆ«ì 2, 3, 5, 7ì„ ë¬´ì‘ìœ„ë¡œ ë°°ì—´í•˜ì—¬ 4ìë¦¬ ìˆ«ìë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ ìˆ«ìê°€ í™€ìˆ˜ì¼ í™•ë¥ ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ? ë‹µì„ ê³µí†µ ë¶„ìˆ˜ë¡œ í‘œí˜„í•˜ì„¸ìš”.\"\n",
    "# qq = \"í‘œì¤€ 6ë©´ ì£¼ì‚¬ìœ„ ë‘ ê°œë¥¼ êµ´ë¦½ë‹ˆë‹¤. ì£¼ì‚¬ìœ„ë¥¼ êµ´ë ¤ ë‚˜ì˜¨ í•©ì´ ì™„ë²½í•œ ì œê³±ìˆ˜ì¼ í™•ë¥ ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?\"\n",
    "# qq = \"\"\"\\\n",
    "# 'question': 'ì›ê°€, í’ˆì§ˆ, ì„œë¹„ìŠ¤, ì†ë„ì™€ ê°™ì€ ì£¼ìš” ì„±ê³¼ì¸¡ì •ì¹˜ì˜ ê·¹ì ì¸ ê°œì„ ì„ ìœ„í•´ ì—…ë¬´í”„ë¡œì„¸ìŠ¤ë¥¼ ê¸‰ì§„ì ìœ¼ë¡œ ì¬ì„¤ê³„í•˜ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€?',\n",
    "#  'A': 'BSC (Balanced Scorecard)',\n",
    "#  'B': 'BPR (business process reengineering)',\n",
    "#  'C': 'CALS (Commerce At Light Speed)',\n",
    "#  'D': 'EIS (Executive Information System)',\n",
    "# \"\"\"\n",
    "# qq=\"\"\"\\\n",
    "# ì„¸ ë³€ì˜ ê¸¸ì´ê°€ ê°ê° 10cm, 8cm, 6cmì¸ ì§ê° ì‚¼ê°í˜•ì´ ìˆìŠµë‹ˆë‹¤. ë‘˜ëŸ¬ì‹¸ì¸ ì›ì˜ ë°˜ì§€ë¦„ì˜ ê¸¸ì´ëŠ” ì–¼ë§ˆì…ë‹ˆê¹Œ?\n",
    "# \"\"\"\n",
    "# qq = \"ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ì˜ ê°€ê²© ì±…ì •ì— ëŒ€í•´ ë…¼ì˜í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤. ë¹„ë°°ë‹¹ ì£¼ì‹ì— ëŒ€í•œ ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ì€ ìœ ëŸ½ì‹ ì½œ ì˜µì…˜ê³¼ ë¹„êµí•  ë•Œ ì¡°ê¸° ì‹¤í–‰ì´ ìµœì ì´ ì•„ë‹ˆë¼ê³  ì£¼ì¥í•˜ëŠ” ì—¬ëŸ¬ ìë£Œê°€ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í•´ë‹¹ ì£¼ì‹ì´ ë°°ë‹¹ê¸ˆì„ ì§€ê¸‰í•˜ì§€ ì•Šì„ ê²½ìš° ìœ ëŸ½ì‹ ì˜µì…˜ê³¼ ì•„ë©”ë¦¬ì¹¸ ì˜µì…˜ì´ ë™ì¼í•˜ë‹¤ëŠ” ì£¼ì¥ë„ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ì™€ ê´€ë ¨í•˜ì—¬ ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ì˜ ê°€ê²©ì„ ë‹¤ìŒì˜ ë‘ ê°€ì§€ í‘œí˜„ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤ê³  ê°€ì •í•˜ì‹­ì‹œì˜¤: 1. ìœ ëŸ½ì‹ ì½œ ì˜µì…˜ ê°€ê²©ì˜ ê²½ìš°: $$V_n(\\omega) = \\frac{1}{1+r} (PV_{n+1}(\\omega H) + QV_{n+1}(\\omega T))$$ 2. ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ ê°€ê²©ì˜ ê²½ìš°: $$V_n(\\omega) = max(S(\\omega) - K, \\frac{1}{1+r} (PV_{n+1}(\\omega H) + QV_{n+1}(\\omega T)))$$ ì´ë•Œ, ë¹„ë°°ë‹¹ ì£¼ì‹ì— ëŒ€í•´ ê¹Šì€ ì¸ë”ë¨¸ë‹ˆ ìƒíƒœì˜ ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ì´ ë§Œê¸° ì „ì— ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•  ë•Œ, ì´ ì˜µì…˜ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ì§€ ì„¤ëª…í•˜ì‹­ì‹œì˜¤. ë˜í•œ ì•„ë©”ë¦¬ì¹¸ ì½œ ì˜µì…˜ì˜ ì¡°ê¸° ì‹¤í–‰ì´ ìµœì ì´ ì•„ë‹ ê²½ìš°, ì™œ (2)ì˜ ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì˜µì…˜ì— ëŒ€í•œ ê°€ê²©ì„ ì •í•´ì•¼ í•˜ëŠ”ì§€ ê·¸ ì´ìœ ë¥¼ ë…¼ì˜í•˜ì„¸ìš”.\"\n",
    "qq = \"ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì•„ì‹œì•ˆ ì˜µì…˜ ê°€ê²©ì˜ ê²½ê³„ ì¡°ê±´ì— ëŒ€í•´ ì„¤ëª…í•˜ì‹œì˜¤. ì£¼ì–´ì§„ í™•ë¥ ì  ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: \\[ dX_t=(-a_1X_t+\\gamma_t)dt+dW_t \\] ë˜í•œ, ë‹¤ìŒê³¼ ê°™ì€ ì •ì˜ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤: \\[ Y_t=\\int_{0}^{t}X_u du \\] ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: \\[ v(t,0,y)=e^{-r(T-t)}\\max\\left(\\frac{y}{T}-K,0\\right) \\] ì´ ìƒí™©ì—ì„œ \\(X_t=0\\)ì´ê³  \\(Y_t=y\\)ì¼ ë•Œ, \\(X_u=0\\)ê°€ ì„±ë¦½í•˜ë©° \\(u \\in [t,T]\\)ì˜ ëª¨ë“  ë²”ìœ„ì—ì„œ \\(Y_u\\)ëŠ” ìƒìˆ˜ë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ \\(Y_T=y\\)ê°€ ì„±ë¦½í•˜ê³ , ë”°ë¼ì„œ ì‹œê°„ \\(t\\)ì—ì„œ ì•„ì‹œì•ˆ ì½œ ì˜µì…˜ì˜ ê°€ì¹˜ëŠ” \\(e^{-r(T-t)}\\max\\left(\\frac{y}{T}-K,0\\right)\\)ë¡œ í‘œí˜„ëœë‹¤ëŠ” ì£¼ì¥ì„ ë³´ì´ì‹œì˜¤. ì´ëŸ¬í•œ ì£¼ì¥ì„ í†µí•´ ì£¼ì–´ì§„ ê²½ê³„ ì¡°ê±´ì˜ ì˜ë¯¸ë¥¼ ë…¼ì¦í•˜ì‹œì˜¤.\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    qq,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "print('------<v1>------')\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs)[0])\n",
    "\n",
    "# print('------<v11>------')\n",
    "      \n",
    "# outputs = model2.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "# print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
