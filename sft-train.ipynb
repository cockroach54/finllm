{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWnZuU7PVtZF"
   },
   "source": [
    "# SFT (Supervised Fine Tuning) for LLM\n",
    "- 금융언어모델 학습\n",
    "- instruction tuning\n",
    "- 추론능력 향상 및 지시에 맞는 답변 포맷팅 목적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNfOabrCVtZH"
   },
   "source": [
    "## 모델 및 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = 'hf_****'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sK96swGiVtZH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2024.12.2: Fast Qwen2 patching. Transformers:4.47.0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 80GB HBM3. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18431a84f2254d51b3a8f022fec4a237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 1500\n",
    "# max_seq_length = 1024\n",
    "# max_seq_length = 2000\n",
    "dtype = None # None으로 지정할 경우 해당 컴퓨팅 유닛에 알맞은 dtype으로 저장됩니다. Tesla T4와 V100의 경우에는 Float16, Ampere+ 이상의 경우에는 Bfloat16으로 설정됩니다.\n",
    "load_in_4bit = False # 메모리 사용량을 줄이기 위해서는 4bit 양자화를 사용하실 것을 권장합니다.\n",
    "\n",
    "# 모델 및 토크나이저 선언\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"lsw0570168/krx-q25-7b-base-v7.2-fft\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token, # gated model을 사용할 경우 허깅페이스 토큰을 입력해주시길 바라겠습니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u2mlY9pMVtZH"
   },
   "outputs": [],
   "source": [
    "# lora 학습시 활성화\n",
    "\n",
    "# model = FastLanguageModel.get_peft_model(\n",
    "#     model,\n",
    "#     r = 32,  # 16, # 0을 넘는 숫자를 선택하세요. 8, 16, 32, 64, 128이 추천됩니다.\n",
    "#     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "#                       \"gate_proj\", \"up_proj\", \"down_proj\",], # target module도 적절하게 조정할 수 있습니다.\n",
    "#     lora_alpha = 16,\n",
    "#     lora_dropout = 0, # 어떤 값이든 사용될 수 있지만, 0으로 최적화되어 있습니다.\n",
    "#     bias = \"none\",    # 어떤 값이든 사용될 수 있지만, \"none\"으로 최적화되어 있습니다.\n",
    "#     use_gradient_checkpointing = \"unsloth\", # 매우 긴 context에 대해 True 또는 \"unsloth\"를 사용하십시오.\n",
    "#     random_state = 42,\n",
    "#     use_rslora = False,\n",
    "#     loftq_config = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loDn97x9VtZH"
   },
   "source": [
    "## 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 1949\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import random\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    err_cnt = 0\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data.append(json.loads(line.strip()))\n",
    "            except Exception as e:\n",
    "                err_cnt += 1\n",
    "    if err_cnt > 0:\n",
    "        print(f\"err line count: {err_cnt}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "with open('./sft_kbench-p.json', 'r') as f:\n",
    "    dd = json.load(f)\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "ds = Dataset.from_dict(\n",
    "    {'formatted_text': [f\"{x}{EOS_TOKEN}\" for x in dd]}\n",
    ")#.shuffle(seed=777).select(range(2000))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "### 질문: 다음 데이터프레임에서 'GDP' 값이 가장 큰 해의 'Year' 값을 구하세요.\n",
      "\n",
      "### df.head()\n",
      "|    | Year | GDP      |\n",
      "|----|------|----------|\n",
      "|  0 | 2010 | 15000.0  |\n",
      "|  1 | 2011 | 15500.5  |\n",
      "|  2 | 2012 | 16000.0  |\n",
      "|  3 | 2013 | 16250.0  |\n",
      "|  4 | 2014 | 17000.0  |\n",
      "\n",
      "### 선택지:\n",
      "A. df.loc[df['GDP'].idxmax(), 'Year']\n",
      "B. df[df['GDP'] == df['GDP'].max()]['Year']\n",
      "C. df['Year'][df['GDP'].idxmax()]\n",
      "D. df.loc[df['Year'].idxmax(), 'GDP']\n",
      "E. df[df['GDP'].argmax()]['Year']\n",
      "F. df[df['GDP'] == df['GDP'].max()].Year.iloc[0]\n",
      "### 정답: 먼저 차근차근 한 단계씩 생각해봅시다.\n",
      "#### step1. 문제 이해:\n",
      "문제는 데이터프레임에서 'GDP' 값이 가장 큰 해의 'Year' 값을 찾는 것입니다. 이는 데이터프레임의 특정 열에서 최대값을 찾고, 그에 해당하는 다른 열의 값을 추출하는 문제로, 판다스 라이브러리를 사용하여 해결할 수 있습니다.\n",
      "#### step2. 각 보기별 문제 풀이:\n",
      "각 보기별로 분석해보겠습니다.\n",
      "A. df.loc[df['GDP'].idxmax(), 'Year'] - 'GDP'의 최대값 인덱스를 찾아 해당 인덱스의 'Year' 값을 반환합니다. 올바른 방법입니다.\n",
      "B. df[df['GDP'] == df['GDP'].max()]['Year'] - 'GDP'의 최대값과 같은 행을 필터링하여 'Year' 값을 반환합니다. 올바른 방법입니다.\n",
      "C. df['Year'][df['GDP'].idxmax()] - 'GDP'의 최대값 인덱스를 찾아 'Year' 열에서 해당 인덱스의 값을 반환합니다. 올바른 방법입니다.\n",
      "D. df.loc[df['Year'].idxmax(), 'GDP'] - 'Year'의 최대값 인덱스를 찾아 'GDP' 값을 반환합니다. 잘못된 방법입니다.\n",
      "E. df[df['GDP'].argmax()]['Year'] - 'argmax()'는 numpy 함수로, 판다스에서는 'idxmax()'를 사용해야 합니다. 잘못된 방법입니다.\n",
      "F. df[df['GDP'] == df['GDP'].max()].Year.iloc[0] - 'GDP'의 최대값과 같은 행을 필터링하여 'Year' 값을 반환합니다. 올바른 방법입니다.\n",
      "#### step3. 전체 풀이 검증:\n",
      "A, B, C, F는 모두 'GDP'의 최대값에 해당하는 'Year' 값을 올바르게 반환합니다. D는 잘못된 열을 참조하고 있으며, E는 잘못된 함수를 사용하고 있습니다.\n",
      "#### step4. 최종 정답:\n",
      "올바른 정답은 A, B, C, F입니다. 이 중 하나를 선택하면 됩니다.\n",
      "### 정답: A<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(ds['formatted_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 2200\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd4 = load_jsonl('./qa_all.jsonl')\n",
    "dd4 = [aaa for aaa in dd4 if len(aaa['question']) > 230]\n",
    "dd42 = load_jsonl('./error_note.jsonl')\n",
    "dd4 = dd4 + dd42 + dd42\n",
    "ds4 = Dataset.from_dict(\n",
    "    {'formatted_text': [f\"{x['question']}\\n\\n{x['answer']}{EOS_TOKEN}\" for x in dd4]}\n",
    ").shuffle(seed=777)#.select(range(5000))\n",
    "ds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = load_dataset(\"kuotient/orca-math-korean-preference\", split='train') \\\n",
    "    .rename_columns({'question': \"prompt\", \"answer\": \"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 2418\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = load_dataset(\"ChuGyouk/argilla-distilabel-math-preference-dpo-korean\", split='train') \\\n",
    "    .rename_columns({'instruction_ko': \"prompt\", \"chosen_response_ko\": \"response\", \"chosen_response\":\"response_en\"}) \\\n",
    "    .select_columns(['prompt', 'response', 'response_en'])\n",
    "\n",
    "rr2 = [\n",
    "    f\"다음 한국어 문장을 영어로 번역하시오.\\n\\n### 한국어:\\n{x['response']}\\n\\n### 영어:\\n{x['response_en']}\" \\\n",
    "    for x in rs2.to_list()[:int(len(rs2)/2)]\n",
    "]\n",
    "rr22 = [\n",
    "    f\"Translate English statement below to Korean.\\n\\n### English:\\n{x['response_en']}\\n\\n### Korean:\\n{x['response']}\" \\\n",
    "    for x in rs2.to_list()[int(len(rs2)/2):]\n",
    "]\n",
    "tmp = Dataset.from_dict({\n",
    "    \"prompt\": ['']*len(rr2+rr22), \"response\": rr2+rr22\n",
    "})\n",
    "\n",
    "rs2 = concatenate_datasets([rs2]) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777)#.select(range(2000))\n",
    "rs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = load_dataset(\"MarkrAI/KoCommercial-Dataset\", split='train') \\\n",
    "    .rename_columns({'instruction':\"prompt\", \"output\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs4 = load_dataset(\"dhruvnathawani/gretelai_synthetic-gsm8k-reflection-405b_validated_with_o1-mini_validation_only\", split='train') \\\n",
    "    .rename_columns({'question':\"prompt\", \"answer\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs5 = load_dataset(\"heegyu/CoT-collection-ko\", split='train') \\\n",
    "    .select_columns(['source', 'rationale']) \\\n",
    "    .rename_columns({'source':\"prompt\", \"rationale\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rs5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs6 = load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split='train') \\\n",
    "    .select_columns(['document', 'summary']) \\\n",
    "    .rename_columns({'document':\"prompt\", \"summary\":\"response\"}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777).select(range(5000))\n",
    "rr6 = [\n",
    "    f\"다음 뉴스 본문을 요약하시오.\\n\\n### 뉴스본문:\\n{x['prompt']}\\n\\n### 요약:\\n{x['response']}\" \\\n",
    "    for x in rs6.to_list()\n",
    "]\n",
    "rs6 = Dataset.from_dict({\"prompt\": ['']*len(rr6), \"response\": rr6}) \\\n",
    "    .select_columns(['prompt', 'response']) \\\n",
    "    .shuffle(seed=777)#.select(range(2000))\n",
    "rs6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af082a867f6d419ba9f05ef4d84a78c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'formatted_text'],\n",
       "    num_rows: 2250\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_format = \"{}\\n\\n{}\"\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"prompt\"]\n",
    "    outputs = examples[\"response\"]\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        text = prompt_format.format(instruction, output) + EOS_TOKEN # 마지막에 eos token을 추가해줌으로써 모델이 출력을 끝마칠 수 있게 만들어 줍니다.\n",
    "        # text = 'axf'*10000+prompt_format.format(instruction, output) + EOS_TOKEN # 마지막에 eos token을 추가해줌으로써 모델이 출력을 끝마칠 수 있게 만들어 줍니다.\n",
    "        texts.append(text)\n",
    "    return { \"formatted_text\" : texts, }\n",
    "pass\n",
    "\n",
    "ds_comb = concatenate_datasets([rs, rs2, rs3, rs4, rs5, rs6])\n",
    "\n",
    "_dataset = ds_comb.map(formatting_prompts_func, batched = True,)\n",
    "_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_text'],\n",
       "    num_rows: 4511\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = concatenate_datasets([ds, _dataset]) \\\n",
    "            .select_columns(['formatted_text']) \\\n",
    "            .shuffle(seed=777)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "### 질문: 다음 중 단기매매증권 평가손익에 대한 설명으로 옳은 것은 무엇인가?\n",
      "### 선택지:\n",
      "A. 단기매매증권 평가손익은 자본잉여금으로 처리한다.\n",
      "B. 단기매매증권 평가손익은 기타포괄손익으로 처리한다.\n",
      "C. 단기매매증권 평가손익은 당기손익으로 처리한다.\n",
      "D. 단기매매증권 평가손익은 미처분이익잉여금으로 처리한다.\n",
      "### 정답: \n",
      "1. 문제 유형: 정의 기반\n",
      "\n",
      "2. 문제 풀이 전략:\n",
      "   - 정의 기반 문제의 경우, 관련 용어의 정의나 원칙을 정확히 이해하고 있어야 합니다. 따라서, 문제에서 언급된 용어(예: 단기매매증권 평가손익)에 대한 회계 기준이나 원칙을 검토하여 올바른 처리를 선택합니다.\n",
      "\n",
      "3. 세부 풀이 과정:\n",
      "   - 단기매매증권은 기업이 단기적인 시세 차익을 목적으로 보유하는 금융자산입니다. 이러한 증권은 공정가치로 평가되며, 평가손익은 당기손익으로 인식됩니다.\n",
      "   - 이는 국제회계기준(IFRS) 및 한국채택국제회계기준(K-IFRS)에서 규정하는 바에 따라, 단기매매증권의 평가손익은 손익계산서에 반영되어 당기손익으로 처리됩니다.\n",
      "   - 따라서, 보기 중에서 단기매매증권 평가손익을 당기손익으로 처리한다고 설명한 선택지를 찾습니다.\n",
      "\n",
      "최종적으로, 정답은 C. 단기매매증권 평가손익은 당기손익으로 처리한다.\n",
      "### 정답: C<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['formatted_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import seaborn as sns\n",
    "\n",
    "# res3 = []\n",
    "# for x in tqdm(dataset['formatted_text']):\n",
    "#     res3.append(len(tokenizer.encode(x)))\n",
    "\n",
    "# print(len([x for x in res3 if x>max_seq_length]))\n",
    "# sns.histplot(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 너무 긴 데이터는 잘못된 데이터일 가능성 크므로 제외!\n",
    "\n",
    "# idxs = [i for i,x in enumerate(res3) if x>3000]\n",
    "# print(len(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.filter(lambda x, i: i not in idxs, with_indices=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNT3z9nNVtZH"
   },
   "source": [
    "## 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import wandb\n",
    "\n",
    "# 고정 설정\n",
    "os.environ['WANDB_PROJECT']=\"krx\"\n",
    "os.environ['WANDB_API_KEY']=\"****\"\n",
    "os.environ['WANDB_ENTITY']=\"****\"\n",
    "\n",
    "# 개별 설정\n",
    "os.environ['WANDB_TAGS']=\"\"\n",
    "run_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "n7K5p11fVtZH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251334f522a4488ba11c98a1293b7ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/4511 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 16,\n",
    "    packing = False, # True로 설정하면 짧은 텍스트 데이터에 대해서는 더 빠른 학습 속도로를 보여줍니다.\n",
    "    args = TrainingArguments( # TrainingArguments는 자신의 학습 환경과 기호에 따라 적절하게 설정하면 됩니다.\n",
    "        per_device_train_batch_size = 2,  # A10(22g) - aws\n",
    "        gradient_accumulation_steps = 8,        \n",
    "        # per_device_train_batch_size = 48,  # H100(80g)\n",
    "        # gradient_accumulation_steps = 1,\n",
    "        # warmup_steps = 100,\n",
    "        warmup_ratio = 0.06,\n",
    "        num_train_epochs = 2,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-5,\n",
    "        # learning_rate = 1e-5,\n",
    "        # learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_hf\",\n",
    "        # optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",  # \"linear\",\n",
    "        seed = 777,\n",
    "        output_dir = \"outputs_sft\",\n",
    "        save_strategy = \"no\",\n",
    "        # save_steps = 1000,\n",
    "        # save_total_limit = 2,\n",
    "        # report_to=\"none\",\n",
    "        report_to = \"wandb\",\n",
    "        run_name = run_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H100 80GB HBM3. Max memory = 79.109 GB.\n",
      "14.689 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer_stats = trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb 로깅 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9S7MWeVtZI"
   },
   "source": [
    "## 5. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [],
   "source": [
    "# # LoRA Adapter 저장\n",
    "# model.save_pretrained(\"lora_model\")\n",
    "# tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [],
   "source": [
    "# # # Merged model 저장\n",
    "# local_model_save_path = \"sft-v7.2-1206-hq2-prc3\"\n",
    "# model.save_pretrained_merged(local_model_save_path, tokenizer, save_method = \"merged_16bit\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = lsw0570168.\n",
      "We shall truncate lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6 to krx-q25-7b-sft-v7.2-1206-hq2-prc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 671.96 out of 1007.38 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 993.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving to organization with address lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e41de8fced44f2a891dd8ce633f1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da9e2fb23d6454ba1ee216260e6750e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merged model 업로드\n",
    "import requests\n",
    "\n",
    "deploy_name = 'lsw0570168/krx-q25-7b-sft-v7.2-1206-hq2-prc6'\n",
    "model.push_to_hub_merged(deploy_name, tokenizer, save_method = \"merged_16bit\", token = hf_token) # 개인 huggingface token을 사용하여 업로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZl4bf7ZVtZI"
   },
   "source": [
    "## 6. 모델 추론 및 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sHa2tCFgVtZI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "\n",
      "### 질문:\n",
      "의무 위반의 효과로 보험자가 그 보험계약을 해지할 수 있다고 상법에 명시되지 않은 것을 고르시오. (다툼이 있는 경우 판례에 따름)**\n",
      "\n",
      "### 선택지:\n",
      "A. 보험계약 당시, 보험계약자나 피보험자가 고의 또는 중대한 과실로 인해 중요한 사항을 고지하지 않거나 부실하게 고지한 경우  \n",
      "B. 보험기간 중, 보험계약자 또는 피보험자가 사고 발생 위험이 현저히 변경되거나 증가된 사실을 알았음에도 지체 없이 보험자에게 통지하지 않은 경우  \n",
      "C. 보험계약자, 피보험자 또는 보험수익자가 보험사고의 발생을 알았을 때, 이를 지체 없이 보험자에게 통지하지 않은 경우  \n",
      "D. 보험기간 중, 보험계약자, 피보험자 또는 보험수익자의 고의 또는 중대한 과실로 인해 사고 발생 위험이 현저히 변경되거나 증가된 경우\n",
      "### 정답:\n",
      "#### Step 1: 문제의 의도 파악 및 유형 분류\n",
      "- **문제의 의도**: 보험계약에서의 의무 위반으로 인해 보험자가 보험계약을 해지할 수 있는 경우를 식별하는 문제입니다.\n",
      "- **핵심 개념**: 보험계약의 해지 사유, 의무 위반, 고지의무, 통지의무\n",
      "- **문제 유형**: 분류 문제 - 주어진 보기 중 상법에 명시되지 않은 보험계약 해지 사유를 찾는 문제입니다.\n",
      "\n",
      "#### Step 2: 풀이 계획 수립\n",
      "- 각 보기에서 제시된 상황이 상법에 명시된 보험계약 해지 사유인지 확인합니다.\n",
      "- 상법에 명시되지 않은 경우를 찾기 위해 각 보기를 검토합니다.\n",
      "\n",
      "#### Step 3: 각 보기별 문제 풀이 및 검토\n",
      "- **A. 보험계약 당시, 보험계약자나 피보험자가 고의 또는 중대한 과실로 인해 중요한 사항을 고지하지 않거나 부실하게 고지한 경우**\n",
      "  - 상법 제643조에 따르면, 보험계약자나 피보험자가 중요한 사항을 고지하지 않거나 부실하게 고지한 경우, 보험자는 계약을 해지할 수 있습니다. 따라서 이 경우는 상법에 명시되어 있습니다.\n",
      "\n",
      "- **B. 보험기간 중, 보험계약자 또는 피보험자가 사고 발생 위험이 현저히 변경되거나 증가된 사실을 알았음에도 지체 없이 보험자에게 통지하지 않은 경우**\n",
      "  - 상법 제644조에 따르면, 보험기간 중에 사고 발생 위험이 변경되거나 증가된 사실을 알았음에도 통지하지 않은 경우, 보험자는 계약을 해지할 수 있습니다. 따라서 이 경우도 상법에 명시되어 있습니다.\n",
      "\n",
      "- **C. 보험계약자, 피보험자 또는 보험수익자가 보험사고의 발생을 알았을 때, 이를 지체 없이 보험자에게 통지하지 않은 경우**\n",
      "  - 상법 제645조에 따르면, 보험사고의 발생을 알았을 때 이를 지체 없이 보험자에게 통지하지 않은 경우, 보험자는 계약을 해지할 수 있습니다. 따라서 이 경우도 상법에 명시되어 있습니다.\n",
      "\n",
      "- **D. 보험기간 중, 보험계약자, 피보험자 또는 보험수익자의 고의 또는 중대한 과실로 인해 사고 발생 위험이 현저히 변경되거나 증가된 경우**\n",
      "  - 상법에는 보험기간 중에 보험계약자, 피보험자 또는 보험수익자의 고의 또는 중대한 과실로 인해 사고 발생 위험이 변경되거나 증가된 경우를 명시적으로 해지 사유로 규정하고 있지 않습니다. 따라서 이 경우는 상법에 명시되지 않은 사유입니다.\n",
      "\n",
      "#### Step 4: 풀이 종합, 검토 및 개선\n",
      "- 각 보기를 검토한 결과, D가 상법에 명시되지 않은 보험계약 해지 사유입니다.\n",
      "- 따라서 최종 정답은 D입니다.\n",
      "\n",
      "### 정답: D<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "qq = '''\\\n",
    "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
    "\n",
    "### 질문:\n",
    "의무 위반의 효과로 보험자가 그 보험계약을 해지할 수 있다고 상법에 명시되지 않은 것을 고르시오. (다툼이 있는 경우 판례에 따름)**\n",
    "\n",
    "### 선택지:\n",
    "A. 보험계약 당시, 보험계약자나 피보험자가 고의 또는 중대한 과실로 인해 중요한 사항을 고지하지 않거나 부실하게 고지한 경우  \n",
    "B. 보험기간 중, 보험계약자 또는 피보험자가 사고 발생 위험이 현저히 변경되거나 증가된 사실을 알았음에도 지체 없이 보험자에게 통지하지 않은 경우  \n",
    "C. 보험계약자, 피보험자 또는 보험수익자가 보험사고의 발생을 알았을 때, 이를 지체 없이 보험자에게 통지하지 않은 경우  \n",
    "D. 보험기간 중, 보험계약자, 피보험자 또는 보험수익자의 고의 또는 중대한 과실로 인해 사고 발생 위험이 현저히 변경되거나 증가된 경우\n",
    "### 정답:\n",
    "'''\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    qq,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sHa2tCFgVtZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------<v1>------\n",
      "ight)\\)로 표현된다는 주장을 보이시오. 이러한 주장을 통해 주어진 경계 조건의 의미를 논증하시오. \\(u \\in [t,T]\\)의 모든 범위에서 \\(Y_u\\)는 상수로 유지됩니다. 이로 인해 \\(Y_T=y\\)가 성립하고, 따라서 시간 \\(t\\)에서 아시안 콜 옵션의 가치는 \\(e^{-r(T-t)}\\max\\left(\f\n",
      "rac{y}{T}-K,0)}\\max\\left(\f\n",
      "rac{y}{T}-K,0\n",
      "\n",
      "---\n",
      "\n",
      "**주어진 조건과 아시안 옵션 가격의 경계 조건에 대한 논의**\n",
      "\n",
      "---\n",
      "\n",
      "**1. 문제의 의도와 주어진 조건의 이해**\n",
      "\n",
      "- **확률적 과정**: 주어진 확률적 과정은 다음과 같습니다:\n",
      "  \\[\n",
      "  dX_t = (-a_1 X_t + \\gamma_t) dt + dW_t\n",
      "  \\]\n",
      "  여기서 \\(X_t\\)는 주가나 자산 가격을 나타내며, \\(a_1\\)은 자산의 감쇠율, \\(\\gamma_t\\)는 시간에 따른 자산의 수익률, \\(dW_t\\)는 Wiener 과정(백색 잡음)입니다.\n",
      "\n",
      "- **정의**: \n",
      "  \\[\n",
      "  Y_t = \\int_{0}^{t} X_u du\n",
      "  \\]\n",
      "  이는 시간 \\(t\\)까지의 자산 가격의 누적값을 나타냅니다.\n",
      "\n",
      "- **경계 조건**:\n",
      "  \\[\n",
      "  v(t,0,y) = e^{-r(T-t)} \\max\\left( \\frac{y}{T} - K, 0 \\right)\n",
      "  \\]\n",
      "  여기서 \\(v(t,0,y)\\)는 시간 \\(t\\)에서 자산 가격이 \\(X_t = 0\\)이고 누적값이 \\(Y_t = y\\)일 때의 옵션 가격을 나타냅니다. \\(K\\)는 행사가격, \\(r\\)은 무위험 이자율, \\(T\\)는 만기입니다.\n",
      "\n",
      "- **조건**: \n",
      "  - \\(X_t = 0\\)이고 \\(Y_t = y\\)일 때, \\(X_u = 0\\)이 성립하며, \\(u \\in [t, T]\\)의 모든 범위에서 \\(Y_u\\)는 상수로 유지됩니다.\n",
      "  - 따라서 \\(Y_T = y\\)가 성립합니다.\n",
      "\n",
      "**2. 아시안 콜 옵션의 가치 계산**\n",
      "\n",
      "- **아시안 콜 옵션의 정의**: 아시안 콜 옵션은 만기 시점까지의 자산 가격의 평균을 기준으로 행사가격 \\(K\\)와 비교하여 이익을 얻는 옵션입니다.\n",
      "- **가격 계산**: 주어진 경계 조건에 따라, 시간 \\(t\\)에서의 아시안 콜 옵션의 가치는 다음과 같이 계산됩니다:\n",
      "  \\[\n",
      "  v(t, 0, y) = e^{-r(T-t)} \\max\\left( \\frac{y}{T} - K, 0 \\right)\n",
      "  \\]\n",
      "  - \\(y\\)는 누적값이며, \\(T\\)는 전체 기간 \\(T\\)에 대한 비율입니다.\n",
      "  - \\(\\max\\left( \\frac{y}{T} - K, 0 \\right)\\)는 자산의 평균 가격이 행사가격 \\(K\\)보다 클 때의 이익을 나타냅니다.\n",
      "\n",
      "**3. 주어진 경계 조건의 의미와 논증**\n",
      "\n",
      "- **경계 조건의 의미**: \n",
      "  - \\(X_t = 0\\)이고 \\(Y_t = y\\)일 때, 이는 자산의 현재 가격이 0이고 누적값이 \\(y\\)라는 것을 의미합니다.\n",
      "  - \\(X_u = 0\\)이 \\(u \\in [t, T]\\)에 대해 성립한다는 것은 자산 가격이 이후 기간 동안 일정하게 유지된다는 것을 나타냅니다.\n",
      "  - 따라서 \\(Y_u\\)는 상수로 유지되며, \\(Y_T = y\\)가 성립합니다.\n",
      "\n",
      "- **논증**:\n",
      "  - 자산 가격이 일정하게 유지되면, 누적값 \\(Y_t\\)는 시간에 따라 일정하게 증가합니다.\n",
      "  - 만기 시점 \\(T\\)에서의 누적값 \\(Y_t\\)는 \\(y\\)로 주어지며, 이는 아시안 콜 옵션의 행사가격 결정에 직접적으로 사용됩니다.\n",
      "  - 따라서, 주어진 경계 조건에 따라 아시안 콜 옵션의 가치는 \\(e^{-r(T-t)} \\max\\left( \\frac{y}{t} - K, 0 \\right)\\)로 계산됩니다.\n",
      "\n",
      "**4. 결론**\n",
      "\n",
      "- 주어진 경계 조건은 아시안 콜 옵션의 가치를 계산하는 데 있어 중요한 역할을 합니다.\n",
      "- 자산 가격이 일정하게 유지되므로, 누적값 \\(Y_t\\)는 시간에 따라 일정하게 증가하며, 이는 아시\n"
     ]
    }
   ],
   "source": [
    "# qq = \"일본의 2023년 6월 개정 자금결제법의 주요 변경 사항을 설명하고, 이러한 변경이 일본의 금융시장 및 국제 금융 규제에 미치는 영향을 논의하시오.\"\n",
    "# qq = \"숫자를 10으로 나눈 값은 6입니다. 윤기는 특정 숫자로부터 15를 빼서 결과를 얻었습니다. 그가 얻은 결과는 무엇일까요?\"\n",
    "# qq = \"정국, 지민, 석진, 태형, 남준이 나란히 서 있습니다. 정국은 지민의 오른쪽에, 석진은 지민의 왼쪽에 서 있습니다. 또한 남준은 석진 왼쪽에, 정국은 태형 왼쪽에 서 있습니다. 가장 오른쪽에 서 있는 사람은 누구인가요?\"\n",
    "# qq = \"숫자 2, 3, 5, 7을 무작위로 배열하여 4자리 숫자를 만듭니다. 이 숫자가 홀수일 확률은 얼마입니까? 답을 공통 분수로 표현하세요.\"\n",
    "# qq = \"표준 6면 주사위 두 개를 굴립니다. 주사위를 굴려 나온 합이 완벽한 제곱수일 확률은 얼마입니까?\"\n",
    "# qq = \"\"\"\\\n",
    "# 'question': '원가, 품질, 서비스, 속도와 같은 주요 성과측정치의 극적인 개선을 위해 업무프로세스를 급진적으로 재설계하는 것으로 정의할 수 있는 것은 무엇인가?',\n",
    "#  'A': 'BSC (Balanced Scorecard)',\n",
    "#  'B': 'BPR (business process reengineering)',\n",
    "#  'C': 'CALS (Commerce At Light Speed)',\n",
    "#  'D': 'EIS (Executive Information System)',\n",
    "# \"\"\"\n",
    "# qq=\"\"\"\\\n",
    "# 세 변의 길이가 각각 10cm, 8cm, 6cm인 직각 삼각형이 있습니다. 둘러싸인 원의 반지름의 길이는 얼마입니까?\n",
    "# \"\"\"\n",
    "# qq = \"아메리칸 콜 옵션의 가격 책정에 대해 논의하겠습니다. 다음 질문에 답하십시오. 비배당 주식에 대한 아메리칸 콜 옵션은 유럽식 콜 옵션과 비교할 때 조기 실행이 최적이 아니라고 주장하는 여러 자료가 있습니다. 그러나 해당 주식이 배당금을 지급하지 않을 경우 유럽식 옵션과 아메리칸 옵션이 동일하다는 주장도 존재합니다. 이와 관련하여 아메리칸 콜 옵션의 가격을 다음의 두 가지 표현으로 나타낼 수 있다고 가정하십시오: 1. 유럽식 콜 옵션 가격의 경우: $$V_n(\\omega) = \\frac{1}{1+r} (PV_{n+1}(\\omega H) + QV_{n+1}(\\omega T))$$ 2. 아메리칸 콜 옵션 가격의 경우: $$V_n(\\omega) = max(S(\\omega) - K, \\frac{1}{1+r} (PV_{n+1}(\\omega H) + QV_{n+1}(\\omega T)))$$ 이때, 비배당 주식에 대해 깊은 인더머니 상태의 아메리칸 콜 옵션이 만기 전에 존재한다고 가정할 때, 이 옵션의 가격은 얼마인지 설명하십시오. 또한 아메리칸 콜 옵션의 조기 실행이 최적이 아닐 경우, 왜 (2)의 식을 사용하여 이 옵션에 대한 가격을 정해야 하는지 그 이유를 논의하세요.\"\n",
    "qq = \"다음 조건을 만족하는 아시안 옵션 가격의 경계 조건에 대해 설명하시오. 주어진 확률적 과정은 다음과 같습니다: \\[ dX_t=(-a_1X_t+\\gamma_t)dt+dW_t \\] 또한, 다음과 같은 정의가 주어집니다: \\[ Y_t=\\int_{0}^{t}X_u du \\] 주어진 경계 조건은 다음과 같습니다: \\[ v(t,0,y)=e^{-r(T-t)}\\max\\left(\\frac{y}{T}-K,0\\right) \\] 이 상황에서 \\(X_t=0\\)이고 \\(Y_t=y\\)일 때, \\(X_u=0\\)가 성립하며 \\(u \\in [t,T]\\)의 모든 범위에서 \\(Y_u\\)는 상수로 유지됩니다. 이로 인해 \\(Y_T=y\\)가 성립하고, 따라서 시간 \\(t\\)에서 아시안 콜 옵션의 가치는 \\(e^{-r(T-t)}\\max\\left(\\frac{y}{T}-K,0\\right)\\)로 표현된다는 주장을 보이시오. 이러한 주장을 통해 주어진 경계 조건의 의미를 논증하시오.\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    qq,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "print('------<v1>------')\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs)[0])\n",
    "\n",
    "# print('------<v11>------')\n",
    "      \n",
    "# outputs = model2.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "# print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
